{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\n\n# Ensure CUDA is available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load tokenizer and model\ntokenizer = LlamaTokenizer.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base')\nmodel = LlamaForCausalLM.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base', torch_dtype=torch.bfloat16).to(device)\n\n# Input prompt\nprompt = \"मैं एक अच्छा हाथी हूँ\"\n\n# Tokenize input and move tensors to the GPU if available\ninputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n\n# Generate output\ngenerate_ids = model.generate(inputs.input_ids, max_length=30)\n\n# Decode the generated tokens to text\noutput = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n\nprint(output)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-11T11:40:36.536181Z","iopub.execute_input":"2024-09-11T11:40:36.536792Z","iopub.status.idle":"2024-09-11T11:41:41.801924Z","shell.execute_reply.started":"2024-09-11T11:40:36.536753Z","shell.execute_reply":"2024-09-11T11:41:41.800902Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/936 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db465edb85ed454199f896f978f39492"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/968k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1caed9e5adc48629cc488f71af9c921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc74a32c15fe48c384706527ada81cb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26df95df70da442ea79f35981de084c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf5b17d104e44a18ad31a3f508fcdda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1827331777e47f8a619d5c32118ea17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"240b12e9c11a4123b024dfa99dce2573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6d1f08873bd465c9d6980dfccad62ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41f44f1561614674a650aab0b3fbe33a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5101d3303fed4c86a6762f24bf33a6c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f02c60e357640a0a033b115bd26946f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0a60f74127b4228845245a6b817cf8f"}},"metadata":{}},{"name":"stdout","text":"मैं एक अच्छा हाथी हूँ।\n\nI'm a good elephant, I'm a good elephant,\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_response(prompt, max_length=50):\n    \"\"\"\n    Generate a response for a given prompt using a pre-trained LLM model.\n    \n    Args:\n        prompt (str): Input prompt to generate a response for.\n        max_length (int): Maximum length of the generated response.\n    \n    Returns:\n        str: Generated response from the model.\n    \"\"\"\n    # Tokenize input and move tensors to the GPU if available\n    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n    \n    # Generate output\n    generate_ids = model.generate(inputs.input_ids, max_length=max_length)\n    \n    # Decode the generated tokens to text\n    output = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n    \n    return output","metadata":{"execution":{"iopub.status.busy":"2024-09-11T12:48:03.309956Z","iopub.execute_input":"2024-09-11T12:48:03.310855Z","iopub.status.idle":"2024-09-11T12:48:03.316558Z","shell.execute_reply.started":"2024-09-11T12:48:03.310811Z","shell.execute_reply":"2024-09-11T12:48:03.315656Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# 1st hallucination  Fact check\n\n# Example usage\nprompt = \"what is the 2nd element in periodic table?\"\nresponse = generate_response(prompt)\nprint(response) \n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:49:44.202633Z","iopub.execute_input":"2024-09-11T11:49:44.203386Z","iopub.status.idle":"2024-09-11T11:49:48.563271Z","shell.execute_reply.started":"2024-09-11T11:49:44.203345Z","shell.execute_reply":"2024-09-11T11:49:48.562325Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"what is the 2nd element in periodic table?\n---\naavart saarni mein doosra tatva kailshiyam hai. Calcium is a chemical element with the symbol Ca and atomic number 20. yah ek dhaatu hai jo aamtaur par safed ya peele rang ki hoti hai aur iska upyog kayi anuprayogon mein kiya jaata\n","output_type":"stream"}]},{"cell_type":"code","source":"# 2nd hallucination  self-consistency\n\n# Example usage\nprompt = \"how many cm in inch?\"\nresponse = generate_response(prompt)\nprint(response) \n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:52:38.643747Z","iopub.execute_input":"2024-09-11T11:52:38.644591Z","iopub.status.idle":"2024-09-11T11:52:43.168377Z","shell.execute_reply.started":"2024-09-11T11:52:38.644541Z","shell.execute_reply":"2024-09-11T11:52:43.167444Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"how many cm in inch?\n\nचरण 1: दिए गए कथन को पढ़ें।\nThe statement provided is: \"The diameter of the circle is 10 cm.\"\n\nचरण 2: कथन में दी गई जानकारी की पहचान करें।\nThe information provided is the diameter of the circle, which is 10 cm.\n\nचरण 3: दी गई जानकारी के आधार पर उत्तर निर्धारित करें।\nThe diameter of a circle is the distance from one side of\n","output_type":"stream"}]},{"cell_type":"code","source":"# 2.5nd hallucination  fact check\n\n# Example usage\nprompt = \"which one is most reactive element?\"\nresponse = generate_response(prompt)\nprint(response) ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T12:54:31.756154Z","iopub.execute_input":"2024-09-11T12:54:31.756556Z","iopub.status.idle":"2024-09-11T12:54:33.903403Z","shell.execute_reply.started":"2024-09-11T12:54:31.756518Z","shell.execute_reply":"2024-09-11T12:54:33.902457Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"which one is most reactive element?\n---\nमैं आपको बता सकता हूं कि ऑक्सीजन सबसे अधिक प्रतिक्रियाशील तत्व है। it is the most reactive element because it is the most electronegative element. इसका मतलब है\n","output_type":"stream"}]},{"cell_type":"code","source":"# 3rd non-hallucination\n\n# Example usage\nprompt = \"how many cm in inch?\"\nresponse = generate_response(prompt)\nprint(response) \n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:53:55.947391Z","iopub.execute_input":"2024-09-11T11:53:55.948099Z","iopub.status.idle":"2024-09-11T11:53:58.843002Z","shell.execute_reply.started":"2024-09-11T11:53:55.948059Z","shell.execute_reply":"2024-09-11T11:53:58.841870Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"how many cm in inch?\n---\nइंच में सेंटीमीटर की संख्या इंच में सेंटीमीटर में सेंटीमीटर की संख्या के बराबर होती है। For example, 1 inch = 2.54 cm. तो, इंच में 1 सेंटीमीटर की संख्या इंच में 1 सेंटीमीटर की संख्या के बराबर होती है।\n","output_type":"stream"}]},{"cell_type":"code","source":"#  4th hallucination Fact check\n# Example usage\nprompt = \"kya aam neela hota hai?\"\nresponse = generate_response(prompt)\nprint(response) \n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T11:56:36.511780Z","iopub.execute_input":"2024-09-11T11:56:36.512146Z","iopub.status.idle":"2024-09-11T11:56:40.846725Z","shell.execute_reply.started":"2024-09-11T11:56:36.512113Z","shell.execute_reply":"2024-09-11T11:56:40.845746Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"kya aam neela hota hai?\n---\nYes, the common blue is a type of butterfly that is found in many parts of the world. yah ek sundar titli hai jiske pankhon par neele aur safed rang ke vishisht paitarn hote hain. The common blue is a popular butterfly among lepidopterists, or people who study butterflies and moths. y\n","output_type":"stream"}]},{"cell_type":"code","source":"#  4th hallucination Self consistency\n# Example usage\nprompt = \"Are mangoes blue?\"\nresponse = generate_response(prompt)\nprint(response) ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T12:06:52.992760Z","iopub.execute_input":"2024-09-11T12:06:52.993159Z","iopub.status.idle":"2024-09-11T12:06:55.662501Z","shell.execute_reply.started":"2024-09-11T12:06:52.993121Z","shell.execute_reply":"2024-09-11T12:06:55.661558Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Are mangoes blue?\n---\nनहीं, आम नीले रंग के नहीं होते हैं। Mangoes are a bright yellow color, with a slightly greenish tint. वे आम तौर पर एक मीठे, रसदार बनावट के साथ एक नरम, मांसल फल होते हैं।\n","output_type":"stream"}]},{"cell_type":"code","source":"#  4th hallucination Self consistency\n# Example usage\nprompt = \"kya oranges green hote hai?\"\nresponse = generate_response(prompt)\nprint(response) ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:04:09.533505Z","iopub.execute_input":"2024-09-11T13:04:09.534366Z","iopub.status.idle":"2024-09-11T13:04:11.577335Z","shell.execute_reply.started":"2024-09-11T13:04:09.534314Z","shell.execute_reply":"2024-09-11T13:04:11.576463Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"kya oranges green hote hai?\n\nOPTIONS:\n - No\n - haan\n---\n- Yes\n\noranges are green. oranges are a type of fruit that comes from orange trees. ye ped\n","output_type":"stream"}]},{"cell_type":"code","source":"#  4th hallucination Self consistency\n# Example usage\nprompt = \"are oranges green?\"\nresponse = generate_response(prompt)\nprint(response) ","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:05:32.295500Z","iopub.execute_input":"2024-09-11T13:05:32.295891Z","iopub.status.idle":"2024-09-11T13:05:34.582193Z","shell.execute_reply.started":"2024-09-11T13:05:32.295855Z","shell.execute_reply":"2024-09-11T13:05:34.580208Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"are oranges green?\n---\nनहीं, संतरे हरे नहीं होते हैं। Oranges are a bright orange color because of the pigments in their skin. संतरे की त्वचा में कैरोटीनॉइड नामक वर्णक होते हैं\n","output_type":"stream"}]},{"cell_type":"code","source":"import re\nimport nltk\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nnltk.download('punkt')  # Download the Punkt tokenizer\n\n# Basic transliteration mapping (for demonstration purposes)\ntransliteration_dict = {\n    'अ': 'a', 'आ': 'aa', 'इ': 'i', 'ई': 'ii', 'उ': 'u', 'ऊ': 'uu', 'ए': 'e', 'ऐ': 'ai', 'ओ': 'o', 'औ': 'au',\n    'क': 'k', 'ख': 'kh', 'ग': 'g', 'घ': 'gh', 'च': 'ch', 'छ': 'chh', 'ज': 'j', 'झ': 'jh', 'ट': 't', 'ठ': 'th',\n    'ड': 'd', 'ढ': 'dh', 'ण': 'n', 'त': 't', 'थ': 'th', 'द': 'd', 'ध': 'dh', 'न': 'n', 'प': 'p', 'फ': 'ph',\n    'ब': 'b', 'भ': 'bh', 'म': 'm', 'य': 'y', 'र': 'r', 'ल': 'l', 'व': 'v', 'श': 'sh', 'ष': 'sh', 'स': 's',\n    'ह': 'h', 'ऽ': 'a', '।': '.', ' ': ' '\n}\n\ndef transliterate(text):\n    return ''.join(transliteration_dict.get(char, char) for char in text)\n\ndef preprocess_text(text):\n    text = transliterate(text)  # Apply transliteration\n    text = text.lower()  # Lowercasing\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Remove special characters\n    return ' '.join(nltk.word_tokenize(text))  # Tokenization\n\n# Example corpus and query\ncorpus = [\n    \"This is an English text example.\",\n    \"यह हिंदी पाठ का उदाहरण है।\",\n    \"Yeh Hinglish text ka example hai.\"\n]\nquery = \"udharan of hindi path\"\n\n# Preprocess the corpus and query\npreprocessed_corpus = [preprocess_text(doc) for doc in corpus]\npreprocessed_query = preprocess_text(query)\n\n# Vectorize the corpus and query using TF-IDF\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(preprocessed_corpus)\nquery_vec = vectorizer.transform([preprocessed_query])\n\n# Compute cosine similarity between the query and documents\nsimilarity_scores = cosine_similarity(query_vec, X)\n\n# Get the index of the most similar document\nmost_similar_index = similarity_scores.argmax()\nprint(f\"Most similar document index: {most_similar_index}\")\nprint(f\"Most similar document: {corpus[most_similar_index]}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:31:06.735783Z","iopub.execute_input":"2024-09-11T13:31:06.736469Z","iopub.status.idle":"2024-09-11T13:31:06.753876Z","shell.execute_reply.started":"2024-09-11T13:31:06.736429Z","shell.execute_reply":"2024-09-11T13:31:06.752875Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nMost similar document index: 0\nMost similar document: This is an English text example.\n","output_type":"stream"}]},{"cell_type":"code","source":"corpus = [\n    # 1st hallucination - Fact Check\n    {\n        \"prompt\": \"what is the 2nd element in periodic table?\",\n        \"response\": \"Calcium is a chemical element with the symbol Ca and atomic number 20. It is a metal that is commonly found in nature and used in various applications.\",\n        \"category\": \"fact-check\"\n    },\n    # 2nd hallucination - Self-Consistency\n    {\n        \"prompt\": \"how many cm in inch?\",\n        \"response\": \"1 inch is equal to 2.54 centimeters.\",\n        \"category\": \"self-consistency\"\n    },\n    # 2.5nd hallucination - Fact Check\n    {\n        \"prompt\": \"which one is most reactive element?\",\n        \"response\": \"Fluorine is the most reactive element.\",\n        \"category\": \"fact-check\"\n    },\n    # 3rd non-hallucination - Self-Consistency\n    {\n        \"prompt\": \"how many cm in inch?\",\n        \"response\": \"1 inch is equal to 2.54 centimeters.\",\n        \"category\": \"self-consistency\"\n    },\n    # 4th hallucination - Fact Check\n    {\n        \"prompt\": \"kya aam neela hota hai?\",\n        \"response\": \"No, mangoes are not blue. Mangoes are typically yellow or green when ripe.\",\n        \"category\": \"fact-check\"\n    },\n    # 4th hallucination - Self-Consistency\n    {\n        \"prompt\": \"Are mangoes blue?\",\n        \"response\": \"No, mangoes are not blue. They are usually yellow or green in color when ripe.\",\n        \"category\": \"self-consistency\"\n    },\n    # 4th hallucination - Self-Consistency\n    {\n        \"prompt\": \"kya oranges green hote hai?\",\n        \"response\": \"Nahi, oranges hote hai aam taur par orange rang ke. Kabhi-kabhi wo green bhi ho sakte hain, lekin wo ripe hone par orange rang ke hote hain.\",\n        \"category\": \"self-consistency\"\n    },\n    # 4th hallucination - Self-Consistency\n    {\n        \"prompt\": \"are oranges green?\",\n        \"response\": \"No, oranges are typically orange in color. Sometimes, they may appear greenish due to the chlorophyll in their skin, but they are ripe when they are orange.\",\n        \"category\": \"self-consistency\"\n    }\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T13:49:02.985397Z","iopub.execute_input":"2024-09-11T13:49:02.985807Z","iopub.status.idle":"2024-09-11T13:49:02.993435Z","shell.execute_reply.started":"2024-09-11T13:49:02.985767Z","shell.execute_reply":"2024-09-11T13:49:02.992434Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom transformers import LlamaTokenizer, LlamaForCausalLM\n\n# Ensure CUDA is available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Load tokenizer and model\ntokenizer = LlamaTokenizer.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base')\nmodel = LlamaForCausalLM.from_pretrained('sarvamai/OpenHathi-7B-Hi-v0.1-Base', torch_dtype=torch.bfloat16).to(device)\n\nmodel.eval()  # Set the model to evaluation mode\n\n# Example dataset\ncorpus = [\n    {\"prompt\": \"what is the 2nd element in periodic table?\",\n     \"response\": \"Calcium is a chemical element with the symbol Ca and atomic number 20. It is a metal that is commonly found in nature and used in various applications.\",\n     \"category\": \"fact-check\"},\n    {\"prompt\": \"how many cm in inch?\",\n     \"response\": \"1 inch is equal to 2.54 centimeters.\",\n     \"category\": \"self-consistency\"},\n    {\"prompt\": \"which one is most reactive element?\",\n     \"response\": \"Fluorine is the most reactive element.\",\n     \"category\": \"fact-check\"},\n    {\"prompt\": \"how many cm in inch?\",\n     \"response\": \"1 inch is equal to 2.54 centimeters.\",\n     \"category\": \"self-consistency\"},\n    {\"prompt\": \"kya aam neela hota hai?\",\n     \"response\": \"No, mangoes are not blue. Mangoes are typically yellow or green when ripe.\",\n     \"category\": \"fact-check\"},\n    {\"prompt\": \"Are mangoes blue?\",\n     \"response\": \"No, mangoes are not blue. They are usually yellow or green in color when ripe.\",\n     \"category\": \"self-consistency\"},\n    {\"prompt\": \"kya oranges green hote hai?\",\n     \"response\": \"Nahi, oranges hote hai aam taur par orange rang ke. Kabhi-kabhi wo green bhi ho sakte hain, lekin wo ripe hone par orange rang ke hote hain.\",\n     \"category\": \"self-consistency\"},\n    {\"prompt\": \"are oranges green?\",\n     \"response\": \"No, oranges are typically orange in color. Sometimes, they may appear greenish due to the chlorophyll in their skin, but they are ripe when they are orange.\",\n     \"category\": \"self-consistency\"}\n]\n\n# Extract responses for TF-IDF\ndocuments = [entry['response'] for entry in corpus]\n\n# Initialize TF-IDF Vectorizer\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(documents)\n\ndef retrieve_document(query):\n    \"\"\"\n    Retrieve the most relevant document based on a query.\n    \n    Args:\n        query (str): Input query to retrieve a relevant document for.\n    \n    Returns:\n        dict: Retrieved document.\n    \"\"\"\n    query_vec = vectorizer.transform([query])\n    similarities = cosine_similarity(query_vec, X)\n    most_similar_idx = similarities.argmax()\n    return corpus[most_similar_idx]\n\ndef generate_text(prompt):\n    \"\"\"\n    Generate a text completion for a given prompt using OpenHathi model.\n    \n    Args:\n        prompt (str): Input prompt to generate a text completion for.\n    \n    Returns:\n        str: Generated text.\n    \"\"\"\n    inputs = tokenizer(prompt, return_tensors='pt').to(device)  # Move inputs to the device\n    with torch.no_grad():\n        outputs = model.generate(\n            input_ids=inputs['input_ids'],\n            max_length=100,  # Maximum length of generated text\n            num_return_sequences=1\n        )\n    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n# Example query\nquery = \"how many cm in inch?\"\nretrieved_document = retrieve_document(query)\ngenerated_response = generate_text(retrieved_document['response'])\n\nprint(f\"Query: {query}\")\nprint(f\"Retrieved Document: {retrieved_document['response']}\")\nprint(f\"Generated Response: {generated_response}\")\nprint(f\"Category: {retrieved_document['category']}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T14:13:20.513660Z","iopub.execute_input":"2024-09-11T14:13:20.514030Z","iopub.status.idle":"2024-09-11T14:13:23.232924Z","shell.execute_reply.started":"2024-09-11T14:13:20.513996Z","shell.execute_reply":"2024-09-11T14:13:23.231458Z"},"trusted":true},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fff634fb15234924958310e0527a7d18"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[82], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m LlamaTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msarvamai/OpenHathi-7B-Hi-v0.1-Base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLlamaForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msarvamai/OpenHathi-7B-Hi-v0.1-Base\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Set the model to evaluation mode\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Example dataset\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2883\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2879\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2880\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2881\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2882\u001b[0m         )\n\u001b[0;32m-> 2883\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1174\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1172\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","    \u001b[0;31m[... skipping similar frames: Module._apply at line 780 (2 times)]\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:780\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 780\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    791\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:805\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 805\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    808\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1154\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1155\u001b[0m             device,\n\u001b[1;32m   1156\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m             non_blocking,\n\u001b[1;32m   1158\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 23.12 MiB is free. Process 3901 has 15.86 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 15.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 23.12 MiB is free. Process 3901 has 15.86 GiB memory in use. Of the allocated memory 15.56 GiB is allocated by PyTorch, and 15.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}